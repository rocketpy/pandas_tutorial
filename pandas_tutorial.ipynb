{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_csv?  # or other methods , this command show HELP  info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading Excel files\n",
    "# pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# create a simple data frame\n",
    "df = pandas.DataFrame([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])  #  two rows in table\n",
    "\n",
    "# named columns\n",
    "df = pandas.DataFrame([[1, 2, 3], [6, 7, 8]], columns=[\"one\", \"two\", \"three\"])\n",
    "\n",
    "# named indexes\n",
    "df = pandas.DataFrame([[1, 2, 3], [6, 7, 8]], index=[\"one\", \"two\"])\n",
    "\n",
    "# create df with dictionary\n",
    "df = pandas.DataFrame([{\"Name\": \"John\", \"Surname\": \"Gray\"}, {\"Name\": \"Jack\", \"Surname\": \"Brown\"}])\n",
    "\n",
    "# read csv file \n",
    "df = pandas.read_csv(\"file_name.csv\")  # or path to file \"C:\\\\ ... \"\n",
    "\n",
    "# read excel file\n",
    "df = pandas.read_excel(\"file_name.xlsx\", sheetname=0)  # 0 - start from first page\n",
    "\n",
    "# read json file\n",
    "df = pandas.read_json(\"file_name.json\")\n",
    "df.set_index(\"ID\")\n",
    "\n",
    "# read txt file , comma separated file\n",
    "df = pandas.read_csv(\"file_name.txt\")\n",
    "\n",
    "# read txt file with semicolons (;)\n",
    "df = pandas.read_csv(\"file_name.txt\", sep=\";\")\n",
    "\n",
    "# set header row (default numbers)\n",
    "df = pandas.read_csv(\"file_name.txt\", header=None)  # file txt don't have headers\n",
    "\n",
    "# set column names\n",
    "df.columns = [\"One\", \"Two\", \"Three\"]\n",
    "              \n",
    "# rename index column with other name of column\n",
    "df.set_index(\"One\", inplace=True)\n",
    "\n",
    "# set index columns\n",
    "df.set_index(\"ID\")\n",
    "\n",
    "# show list all rows or columns\n",
    "df.index\n",
    "df.columns\n",
    "\n",
    "# shape of table\n",
    "df.shape\n",
    "\n",
    "# methods of df\n",
    "dir(df)\n",
    "\n",
    "# mean() method , 6 -> 6.0\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing (extracting) , slicing\n",
    "df.loc[1: 5, \"Two\": \"Three\"]  # from 1 to 5 -> names id , from \"Two\" to \"Three\" names columns\n",
    "\n",
    "# slicing with indexes\n",
    "df.iloc[1:5, 2:4]  # from 1 to 5 -> indexes id , from 2 to 4 columns\n",
    "\n",
    "# take all rows of one column\n",
    "df.loc[:, \"Two\"]\n",
    "\n",
    "# show in list \n",
    "list(df.loc[:, \"Two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting columns and rows\n",
    "new_df=df.drop(\"Two\", 1)  # 1 - column \n",
    "new_df=df.drop(name_id, 0)  # 0 - row\n",
    "\n",
    "# deleting by indexes\n",
    "new_df=df.drop(df.index[0:3, 0])\n",
    "new_df=df.drop(df.columns[1:3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to transpose , change sites column names to row site \n",
    "df_t=df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating and adding new rows , columns\n",
    "df[\"name_new_column\"]=df.shape[0]*[\"new_values\"]  # add new column with new values for ich rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# show files in working directory\n",
    "os.listdir()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df\n",
    "df2 = df1.copy()\n",
    "\n",
    "# deepcopy\n",
    "from copy import deepcopy\n",
    "df2 = deepcopy(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check types of values\n",
    "df.dtypes.value_counts()\n",
    "\n",
    "# list of all columns\n",
    "df.columns.tolist()\n",
    "\n",
    "# when read file and need show first 5 rows\n",
    "# need add to read_csv: nrows = 5\n",
    "\n",
    "# to show first 5 rows like in CSV\n",
    "print(df[:5].to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocoding addresses with pandas and geopy\n",
    "# pip install geopy\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import ArcGIS\n",
    "import pandas as pd\n",
    "\n",
    "nom=ArcGIS()\n",
    "\n",
    "# check some address\n",
    "n=nom.geocode(\"# input some address \")\n",
    "\n",
    "df=pd.read_csv(\"filename.csv\")\n",
    "df[\"Address\"]=df[\"Address\"]+\", \"+df[\"City\"]+\", \"+df[\"State\"]+\", \"+df[\"Country\"]\n",
    "\n",
    "df[\"Coordinates\"]=df[\"Address\"].apply(nom.geocode)\n",
    "\n",
    "df.Coordinates[0].latitude\n",
    "\n",
    "df[\"Latitude\"]=df[\"Coordinates\"].apply(lambda x: x.latitude if x != None else None)\n",
    "df[\"Longtitude\"]=df[\"Coordinates\"].apply(lambda x: x.longtitude if x != None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taked from : https://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/top_25_pandas_tricks.ipynb\n",
    "\n",
    "# pandas version\n",
    "pd.__version__\n",
    "pd.show_versions()  # dependencies\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['col_one', 'col_two']\n",
    "\n",
    "# Most flexible option:\n",
    "df = df.rename({'A':'a', 'B':'b'}, axis='columns')\n",
    "\n",
    "# Overwrite all column names:\n",
    "df.columns = ['a', 'b']\n",
    "\n",
    "\n",
    "# reverse row order\n",
    "df.head()\n",
    "df.loc[::-1].head()\n",
    "\n",
    "# reverse column order\n",
    "df.loc[:, ::-1].head()\n",
    "\n",
    "# select column by data type\n",
    "df.dtypes\n",
    "\n",
    "df.select_dtypes(include='number').head()  # include='object' or use list include=['', '', '']\n",
    "\n",
    "df.select_dtypes(exclude='number').head()\n",
    "\n",
    "# convert strings to numbers\n",
    "df.astype({'col_one':'float', 'col_two':'float'}).dtypes  # ONLY for first two columns !!!\n",
    "\n",
    "pd.to_numeric(df.col_three, errors='coerce')\n",
    "\n",
    "pd.to_numeric(df.col_three, errors='coerce').fillna(0)\n",
    "df = df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# reduce DataFrame size\n",
    "df.info(memory_usage='deep') # df = drinks.csv\n",
    "\n",
    "cols = ['beer_servings', 'continent']\n",
    "small_drinks = pd.read_csv('http://bit.ly/drinksbycountry', usecols=cols)\n",
    "small_drinks.info(memory_usage='deep')\n",
    "\n",
    "dtypes = {'continent':'category'}\n",
    "smaller_drinks = pd.read_csv('http://bit.ly/drinksbycountry', usecols=cols, dtype=dtypes)\n",
    "smaller_drinks.info(memory_usage='deep')\n",
    "\n",
    "# build a DataFrame from multiple files   (row-wise) !!!\n",
    "pd.read_csv('data/file_name.csv')\n",
    "pd.read_csv('data/file_name2.csv')\n",
    "pd.read_csv('data/filename3.csv')\n",
    "\n",
    "from glob import glob\n",
    "stock_files = sorted(glob('data/file_name*.csv'))\n",
    "pd.concat((pd.read_csv(file) for file in stock_files))\n",
    "pd.concat((pd.read_csv(file) for file in stock_files), ignore_index=True)\n",
    "\n",
    "\n",
    "# build a DataFrame from multiple files (column-wise)\n",
    "\n",
    "pd.read_csv('data/file_name1.csv').head()\n",
    "pd.read_csv('data/file_name2.csv').head()\n",
    "\n",
    "drink_files = sorted(glob('data/file_name*.csv'))\n",
    "pd.concat((pd.read_csv(file) for file in drink_files), axis='columns').head()\n",
    "\n",
    "\n",
    "# create a DataFrame from the clipboard\n",
    "\n",
    "df = pd.read_clipboard()\n",
    "df.dtypes\n",
    "df.index\n",
    "\n",
    "\n",
    "# filter a DataFrame by multiple categories\n",
    "\n",
    "df.head()\n",
    "df.genre.unique()\n",
    "\n",
    "df[(movies.genre == 'Action') |\n",
    "       (movies.genre == 'Drama') |\n",
    "       (movies.genre == 'Western')].head()\n",
    "df[movies.genre.isin(['Action', 'Drama', 'Western'])].head()\n",
    "df[~df.genre.isin(['Action', 'Drama', 'Western'])].head()\n",
    "\n",
    "\n",
    "# filter a DataFrame by largest categories\n",
    "\n",
    "counts = df.genre.value_counts()\n",
    "counts.nlargest(3)\n",
    "counts.nlargest(3).index\n",
    "df[df.genre.isin(counts.nlargest(3).index)].head()\n",
    "\n",
    "# handle missing values\n",
    "\n",
    "df.head()\n",
    "df.isna().sum()\n",
    "df.isna().mean()\n",
    "df.dropna(axis='columns').head()  #  to drop the columns that have any missing values\n",
    "\n",
    "\n",
    "# select a slice of rows and columns\n",
    "\n",
    "df.head()\n",
    "df.describe()\n",
    "df.describe().loc['min':'max']\n",
    "df.describe().loc['min':'max', 'Pclass':'Parch']\n",
    "\n",
    "\n",
    "# reshape a MultiIndexed series\n",
    "\n",
    "titanic.Survived.mean()\n",
    "titanic.groupby('Sex').Survived.mean()\n",
    "titanic.groupby(['Sex', 'Pclass']).Survived.mean()\n",
    "titanic.groupby(['Sex', 'Pclass']).Survived.mean().unstack()\n",
    "\n",
    "\n",
    "# create a pivot table\n",
    "\n",
    "titanic.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc='mean')\n",
    "titanic.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc='mean', margins=True)\n",
    "titanic.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc='count', margins=True)\n",
    "\n",
    "# convert continuous data into categorical data\n",
    "\n",
    "titanic.Age.head(10)\n",
    "pd.cut(titanic.Age, bins=[0, 18, 25, 99], labels=['child', 'young adult', 'adult']).head(10)\n",
    "\n",
    "\n",
    "# change display options\n",
    "\n",
    "df.head()\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "pd.reset_option('display.float_format')\n",
    "\n",
    "# style a DataFrame it's very cool !!!\n",
    "\n",
    "df\n",
    "\n",
    "format_dict = {'Date':'{:%m/%d/%y}', 'Close':'${:.2f}', 'Volume':'{:,}'}  # Date, Close, Volume is a column names !!!\n",
    "\n",
    "stocks.style.format(format_dict)\n",
    "\n",
    "(stocks.style.format(format_dict)\n",
    " .hide_index()\n",
    " .highlight_min('Close', color='red')\n",
    " .highlight_max('Close', color='lightgreen')\n",
    ")\n",
    "\n",
    "(stocks.style.format(format_dict)\n",
    " .hide_index()\n",
    " .background_gradient(subset='Volume', cmap='Blues')\n",
    ")\n",
    "\n",
    "(stocks.style.format(format_dict)\n",
    " .hide_index()\n",
    " .bar('Volume', color='lightblue', align='zero')\n",
    " .set_caption('Stock Prices from October 2016')\n",
    ")\n",
    "\n",
    "\n",
    "# profile a DataFrame\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "pandas_profiling.ProfileReport(titanic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
